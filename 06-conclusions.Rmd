
# Conclusions

At inception of this thesis work, we hoped that text mining could someday become an everyday tool for the biomedical research community. We were specifically interested in the use of text mining to collate knowledge for the personalized oncology field. This final chapter will discuss how the work undertaken has contributed to these goals and what hurdles remain. We will broadly discuss the lessons learnt during this thesis and suggest interesting future directions to pursue, particularly to overcome some of the limitations acknowledged within this work.

## Contributions

Many research areas are overwhelmed by potential hypotheses to test and automated hypothesis generation methods are designed to provide prioritized lists to researchers. Several factors limit these methods being embraced by the biology research community, including the predictive performance, explainability, and poor awareness that these methods exist. Our work in Chapter 2 pushed forward the predictive performance by developing and evaluating a new approach using co-occurrence data. We showed that our SVD-based method outperformed the previously best performing methods and explored the explainability of some the successful and failed predictions.

Supervised relation extraction is an important step past cooccurrences in information extraction. Our work with the VERSE and Kindred tools in Chapter 3 illustrated that vectorized dependency path-based approaches are the best method for biomedical relation extraction and that deep learning does not achieve the same benefits in other fields with larger training dataset sizes. The VERSE system won part of the BioNLP Shared Task 2016. Furthermore, the packaging of Kindred makes it easier for other researchers to use our methods for their own problems.

Our CancerMine resource, described in Chapter 4, will benefit all cancer biology researchers as a valuable tool to understand the role of different genes in cancer. The high-precision knowledge extraction pipeline proves that single sentences do contain enough information for large-scale knowledge base construction. By examining the frequently cited gene roles, we were able to build profiles for each cancer type that can be used to find similarities between cancers and were validated by comparison to data in the Cancer Genome Atlas (TCGA) project.

Finally Chapter 5 describes the CIVICmine resource designed specifically for curating information about the growing field of precision oncology and the clinical relevance of mutations in cancer. This resource will prove increasingly valuable in the coming years as more medical centres develop precision oncology programs. The methods for annotating the training data and building a classifier that can scale to PubMed provide valuable guidelines for other groups interested in building a high-precision knowledgebase in another area of biology.

## Lessons Learnt

The stated goal of much biomedical text mining research is to help biologists and medical researchers absorb research and identify potential hypotheses for study. With the information overload present in published literature, automated methods should be used to guide researchers to the knowledge that they need. Throughout this thesis work, I have identified several key problems that frequently occur in biomedical text mining. These problems are fruitful areas for future research.

### Inaccessible and out-of-date results

Firstly, and importantly, access to text mined results is key to adoption by researchers. Many research papers develop text mining methods where the code and/or data are not shared. These papers may benefit other text mining researchers with algorithmic improvement ideas or approaches that could be generalized to other text mining problem. But they do not help biologists.

Text mining published literature has been a focus of research for several decades. Advances in computational power within the last 15 years has made it possible to do large-scale processing of a large number of Pubmed abstracts and full-text papers. Hence there have been multiple analyses of Pubmed data, but very few are kept up-to-date as new publications are added to the corpus.

The reason for this lack of updating is primarily that researchers move onto other projects after publication and potentially move to other institutions (especially graduate students). The additional engineering required to maintain text mining results can be too much for a research group. But if text mining is to become a ubiquitous tool for biologists, this must be a problem that is overcome and would be a valuable direction for future work.


### User Interfaces

The way that a biologist can interact with the text-mined data is key. Even if the data is public, most biologists do not understand the value of text mining and would not go to the effort of downloading data and searching it themselves. Hence a user interface is absolutely essential for this development. To be more specific, a graphical user interface is required as few biologists would be willing to use a command-line application.

There are three common paths for building applications with graphical user interfaces. First, the tool can be implemented as a standalone desktop application. These require installation and are often operating system specific (e.g. only running on Windows). The second is as a Java application that can be launched from a website. More web browsers are blocking Java applications by default due to the high-security risks involved in executing a Java application (e.g. access to full file system).

This brings us to the fourth option which I would argue is the only real option these days. With advances in web technologies, specifically AJAX-like libraries, that provide responsive websites for high-quality user experiences, web apps are the best solution. These can be client-side only where all calculations and analysis are done using Javascript code. Or more commonly, with a server-side end with a database, text mining results can be queried quickly. Several bioinformatics analysis tools have been frequently due to their implementation as web applications. The DAVID tool for gene set enrichment analysis [@dennis2003david] is a classic example of a tool that is frequently used when other more up-to-date tools exist but are hard to use.

These arguments lead us to build web apps for the CancerMine and CIViCmine projects. We used the Shiny web technology for its ease of implementation and visually attractive interfaces. Unfortunately Shiny may not scale well to a larger number of users and these interfaces may be revisited if the resources prove very popular. We would encourage other text mining developers to consider providing a web interface to navigate text-mined data.

There is a huge area of research in human-computer interaction (HCI). It could easily be argued that there should be more integration between text mining and HCI research in order to understand what features make a tool easier to use. If a biologist finds a tool frustrating to use, or the results unreliable, they may never use the tool again. The CancerMine and CIViCmine research, fortunately, took place in an environment close to potential users of these resources which provided the opportunity to discuss their design. Understanding the real needs of users and the challenges they face interpreting text-mined data would enable text mining to become a more valuable part of the research process.

## Limitations and Future Directions

One of the main limitations of our work is the focus on the knowledge contained within single sentences. For all of our projects, we only capture co-occurrences or relations that are discussed within a sentence and do not capture knowledge that is spread across multiple sentences. This is a common limitation of many text mining tools at the moment due to the challenge presented by anaphora. Coreference resolution methods still provide noisy results when identifying which specific term a pronoun (or general noun) refer to. We examined the ability to extract relations across sentence boundaries but found (as others have) that the false positive rate skyrockets as more sentences are included. This is largely due to the decrease in class balance, as the positive examples become a small fraction of all possible candidate relations. Overcoming this limitation with a high-quality coreference resolution method would provide the largest gain for relation extraction methods used to populate knowledge bases (as in Chapters 4 and 5).

We are also limited by access to text corpora for information extraction. We chose to focus on PubMed and PubMed Central Open Access subset (PMCOA) as they contain the largest set of published abstracts and full-text articles while also being the easiest to access. Several publishers are beginning to make other smaller corpora accessible through limited APIs (and often requiring special permissions) [@westergaard2018comprehensive]. However, these new corpora provide additional challenges with unique file formats and rights permissions when sharing the results of text mining. This will be the primary stumbling block of biomedical text mining in the coming decades. Several universities have shown the desire to change their relationships with publishers to encourage easier access to literature, both for text mining and for researchers in general. We hope these efforts progress quickly.

In Chapters 4 and 5, we faced a common problem in biomedical text mining. For supervised learning, annotated training data is needed to build a classifier. The size of the training data is a limiting factor for the complexity of the classifier that can be built. The recent successes of deep learning in other fields, particularly computer vision, have been led by the development of vast training sets (e.g. ImageNet [@deng2009imagenet]). In fact, Google acquired reCAPTCHA in order to generate human annotated image data to improve their computer vision algorithms for Google Streetview and Project Gutenberg [@von2008recaptcha]. For the biomedical field, expert annotators may be needed for specific tasks. Some researchers have tried crowdsourcing (e.g. Mark2theCure [@tsueng2016citizen]) either through volunteers or Mechanical Turk paid workers [@buhrmester2011amazon]. These crowdsourcing efforts have shown that many non-expert annotators must look at the same sentence in order to get a good consensus. This increases the annotation cost and drove our decision to use expert-annotators for CancerMine and CIViCmine. However, it created the limitation of a smaller training set size. This smaller training set size meant that a deep learning based approach wasn’t a viable approach given the currently established issue with overfitting small data set sizes [@mehryary2016deep]. The BioNLP Shared Tasks showed that more classical approaches, as taken in Chapter 3, were still the most reliable approach for relation extraction given smaller training set sizes. 

An interesting angle that should be pursued is active learning in which the data for annotation is continuously updated to identify the most confusing sentences for the system. This approach is impeded by the need to use multiple annotators and would likely require small batch active learning instead of continually updated active learning.

The decision to focus on a limited set of relations between the biomedical entities of interest (e.g. genes and cancers) has advantages and disadvantages. In Chapter 4, we were interested in only three relation types (Drivers, Oncogenes and Tumor Suppressors). There are many other relations that can exist between a gene and a cancer type, e.g. “frequently mutated in”. By focussing on only three relation types, we could provide a tightly controlled annotation process with a specific annotation manual. This meant that the annotation task was feasible and could be completed by annotators within an acceptable amount of time. However, we may be missing interesting relations between these entities. Other approaches take an Open Information Extraction (OpenIE) approach where no assumptions are made about the types of relations that may exist [cite Percha]. An approach that could bridge the two methods would be a valuable addition to the biomedical text mining field.

## Final Words

Biomedical text mining should be an every-day tool used by researchers to keep up-to-date with research and help guide their hypothesis generation. To get to this stage, we have contributed several key ideas, methods, and data-sets, including high precision relation extraction for knowledge base construction. This is an exciting period for this field with the culmination of affordable computational resources, web technologies and advances in biomedical sciences. We must work closely with biomedical researchers to understand the problems that matter to them and enable them to interrogate the biomedical knowledge in a form suited to them.
